# =======
# Imports
# =======

import numpy
import scipy

# ============================
# Golub-Kahn Bidiagonalization
# ============================

def GolubKahnBidiagonalization(A,w,m,Tolerance=1e-8):
    """
    B-diagonalizes the positive-definite matrix ``A`` using Golub-Kahn-Lanczos method.

    This method bi-diagonalizes matrix ``A`` to ``B`` using the start vector ``w``. ``m`` is the Lanczos
    degree, which will be the size of square matrix ``B``.

    .. note::

        * ``A`` should be positive-definite matrix size ``n*n``.
        * ``B`` will be positive-definite matrix of size ``(m+1,m+1)``.

    .. warning::

        When matrix ``A`` is very close to the identity matrix, the Golub-Kahn bi-doagonalization method can not 
        find :math:`\\beta`, as :math:`\\beta` becomes zero. If ``A`` is not exactly identity, you may decrease the Tolerance
        to a very small number. However, if ``A`` is almost identity matrix, decreasing tolerance will not 
        help, and this function cannot be used.

    :param A: Input matrix of the size ``n*n``. Matrix should be positive-definite and symmetric.
    :type A: numpy.ndarray

    :param w: Start vector for the Lanczos tri-diagonalization. Column vector of size ``n``.
        It could be generated randomly. Often it is generated by the Rademacher distribution with entries ``+1`` and ``-1``.
    :type w: array

    :param m: Lanczos degree, which is the number of Lanczos iterations.
    :type m: int

    :param Tolerance: The tolerance of the residual error of the Lanczos iteration.
    :type Tolerance: float

    :return: Symmetric positive-definite matrix ``B`` of the size ``(m+1)*(m+1)``.
    :rtype: numpy.ndarray

    Reference:
        * NetLib `Algorithm 6.27 <http://www.netlib.org/utk/people/JackDongarra/etemplates/node198.html>`_
        * Matrix Computations, Golub, p. 495
        * Templates for Solution of Algebraic Eigenvalue Problem, Demmel, p. 143
    """

    # Normalize random vector
    Norm = numpy.linalg.norm(w)
    v = w/Norm

    beta = numpy.zeros(m+1)
    alpha = numpy.zeros(m)
    B = numpy.zeros((m,m))

    # u = numpy.zeros(w.size)
    # beta[0] = 1
    # p = numpy.copy(v)

    # for k in range(m):

    #     v_old = numpy.copy(v)
    #     u_old = numpy.copy(u)

    #     v = p / beta[k]

    #     r = A.dot(v_old) - beta[k]*u_old

    #     alpha[k] = numpy.linalg.norm(r)

    #     u = r/alpha[k]
    #     p = A.T.dot(u) - alpha[k]*v
    #     beta[k+1] = numpy.linalg.norm(p)

    #     if beta[k+1] < Tolerance:
    #         return B[:k,:k]
    #     
    #     # Update B
    #     B[k,k] = alpha[k]

    #     if k < m-1:
    #         B[k,k+1] = beta[k+1]

    # return B

    beta[0] = 0

    v_old = numpy.copy(v)

    for k in range(m):

        if k == 0:
            u_new = A.dot(v_old)
        else:
            u_new = A.dot(v_old) - beta[k]*u_old

        alpha[k] = numpy.linalg.norm(u_new)
        u_new = u_new / alpha[k]

        v_new = A.T.dot(u_new) - alpha[k]*v_old
        beta[k+1] = numpy.linalg.norm(v_new)

        # Exit criterion
        if beta[k+1] < Tolerance:
            if k == 0:
                # raise ValueError('Premature exit at k = 0. beta[0:2] = %0.16f, %0.16f. This happens when A is close to identity. To resolve issue, decrease Tolerance: %f'%(beta[0],beta[1],Tolerance))
                print('Premature exit in Golub-Kahn-Lanczos bi-diagonalization. alpha: %e, beta: %e'%(alpha[0],beta[1]))
                B = numpy.array([[alpha[0]]])
                return B
            return B[:k,:k]

        v_new = v_new / beta[k+1]

        # Store to the output matrix
        B[k,k] = alpha[k]
        if k < m-1:
            B[k,k+1] = beta[k+1]

        # Update for new iteration
        v_old = numpy.copy(v_new)
        u_old = numpy.copy(u_new)

    return B
