# =======
# Imports
# =======

import numpy
import scipy

# ==========================
# Lanczos Tridiagonalization
# ==========================

def LanczosTridiagonalization(A,v,m,Tolerance=1e-8):
    """
    Tri-diagonalizes matrix ``A`` to ``T`` using the start vector ``w``. ``m`` is the Lanczos
    degree, which will be the size of square matrix ``T``.

    .. note::

        * ``A`` should be symmetric and positive-definite matrix size ``n*n``.
        * ``T`` will be symmetric and positve-definite matrix of size ``(m+1,m+1)``.
        
    Comparision of Lanczos tri-diagonalization and Golub-Kahn Bi-diagonalization:
        * The Lanczos tri-diagonalization is twice faster (in run time), as it have only one matrix-vector
          multiplication. Whereas the Golub-Kahn bid-diagonalization has two matrix-vector multiplications.
        * The Lanczos tri-diagonalization can only be applied to symmetric matrices. Whereas the Golub-Kahn
          bi-diagonalization can be applied to any matrix.

    :param A: Input matrix of the size ``n*n``. Matrix should be positive-definite and symmetric.
    :type A: numpy.ndarray

    :param w: Start vector for the Lanczos tri-diagonalization. Column vector of size ``n``.
        It could be generated randomly. Often it is generated by the Rademacher distribution with entries 
        ``+1`` and ``-1``.
    :type w: array

    :param m: Lanczos degree, which is the number of Lanczos iterations.
    :type m: int

    :param Tolerance: The tolerance of the residual error of the Lanczos iteration.
    :type Tolerance: float

    :return: Symmetric positive-definite matrix ``T`` of the size ``(m+1)*(m+1)``.
    :rtype: numpy.ndarray
    """

    beta = numpy.zeros(m+1)
    alpha = numpy.zeros(m)
    T = numpy.zeros((m,m))

    n = v.size
    V = numpy.zeros((n,m))

    r = numpy.copy(v)
    beta[0] = numpy.linalg.norm(r)

    # In the following, beta[j] means beta[j-1] in the Demmel text
    for j in range(m):

        V[:,j] = r / beta[j]

        # Matrix-vector multiplication
        if scipy.sparse.isspmatrix(A):
            r = A.dot(V[:,j])
        else:
            r = numpy.dot(A,V[:,j])

        if j > 0:
            r = r - V[:,j-1]*beta[j]

        alpha[j] = numpy.dot(V[:,j],r)

        r = r - V[:,j]*alpha[j]

        beta[j+1] = numpy.linalg.norm(r)

        # Exit if beta got very small
        if beta[j+1]*(j+1) < Tolerance:
            return T[:j+1,:j+1]

        T[j,j] = alpha[j]
        if j < m-1:
            T[j,j+1] = beta[j+1]
            T[j+1,j] = beta[j+1]

    return T
